# This playbook setups the local context to the provisioned cluster
- hosts: localhost
  vars:
    # this file has been fetched from the lnx_setup host, by the lnxclp-new role
    # playbook_dir is undocumented, but check the source:
    # https://github.com/ansible/ansible/blob/143bafec9a506aff8f42ca573c7006a8c5549e12/lib/ansible/vars/hostvars.py#L40
    local_path: "{{playbook_dir}}/../../.local"
    admin_conf: "{{local_path}}/admin.conf"
    script_path: "{{local_path}}/scripts"
    log_path: "{{local_path}}/scripts/log"

  tasks:
    - name: "clusterlocal - ensure .local directories exists"
      file:
        path: "{{item}}"
        state: directory
      with_items:
        - "{{script_path}}"
        - "{{log_path}}"

    - name: "clusterlocal - validate {{admin_conf}} exists"
      stat: path="{{local_path}}/admin.conf"
      register: res
      failed_when: res.stat.exists != true

    - name: clusterlocal - sync install-tools script
      template:
        src: localtemplates/install-tools
        dest: "{{script_path}}/install-tools"
        mode: 344

    - name: clusterlocal - sync import-admin.conf script
      template:
        src: localtemplates/import-admin.conf
        dest: "{{script_path}}/import-admin.conf"
        mode: 344

    - name: clusterlocal - sync use-context script
      template:
        src: localtemplates/use-context
        dest: "{{script_path}}/use-context"
        mode: 344

    - name: "clusterlocal - run install-tools (log in {{log_path}}/install-tools.log)"
      shell: "{{script_path}}/install-tools > {{log_path}}/install-tools.log"
      register: cmd
      failed_when: cmd.rc > 0 and cmd.rc < 255
      changed_when: cmd.rc == 0

    - name: "clusterlocal - run 'use-context' for setup and verification (log in {{log_path}}/use-context.log)"
      shell: "{{script_path}}/use-context > {{log_path}}/use-context.log"
      register: cmd
      failed_when: cmd.rc > 0 and cmd.rc < 255
      changed_when: cmd.rc == 0

    - name: clusterlocal -- if singlenode cluster, remove taint to schedule on master
      shell: kubectl taint node --all node-role.kubernetes.io/master-
      register: cmd
      failed_when: false
      changed_when: cmd.rc == 0
      when: global_vagrant_singlenode_lnxcluster == true

    - name: clusterlocal - sync write-k8s-setup-info script
      template:
        src: localtemplates/write-k8s-setup-info
        dest: "{{script_path}}/write-k8s-setup-info"
        mode: 344

    - name: clusterlocal - run 'write-k8s-setup-info' to persist metadata as configmap
      shell: "{{script_path}}/write-k8s-setup-info"
      register: cmd
      failed_when: cmd.rc > 0 and cmd.rc < 255
      changed_when: cmd.rc == 0

    # TODO: this is just a workaround for https://github.com/world-direct/k8s-setup/issues/77
    - name: clusterlocal - workaround for Issue \#77 scale coredns down to 1 replica
      shell: kubectl -n kube-system scale deployment coredns --replicas=1
      when: global_mode == "vagrant"